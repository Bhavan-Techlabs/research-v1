# Research Assistant Platform - Environment Configuration
# This file contains ONLY MongoDB and optional configuration settings
# 
# ⚠️ IMPORTANT: LLM API Keys are NOT configured here!
# LLM API keys are configured at runtime through the Settings page in the application.
# This provides better security and multi-user support.
#
# Copy this file to .env and configure your settings:
# cp .env.example .env

# ============================================
# REQUIRED: MongoDB Configuration
# ============================================
# MongoDB is required for:
# - LLM provider configurations
# - Embedding model configurations  
# - User-created research prompts
#
# Option 1: Local MongoDB
MONGODB_URI=mongodb://localhost:27017/
#
# Option 2: MongoDB Atlas (Cloud)
# MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/?retryWrites=true&w=majority
#
# Option 3: MongoDB with authentication
# MONGODB_URI=mongodb://username:password@localhost:27017/?authSource=admin

# Database name (default: research_assistant)
MONGODB_DATABASE=research_assistant

# Collection names (optional - defaults shown)
MONGODB_COLLECTION_PROMPTS=prompts
MONGODB_COLLECTION_MODELS=models
MONGODB_COLLECTION_EMBEDDINGS=embedding_models

# ============================================
# OPTIONAL: Search APIs
# For enhanced Google Scholar search capability
# ============================================
# Google Custom Search (for web search)
# Get API key at: https://console.cloud.google.com/apis/credentials
# Get CSE ID at: https://programmablesearchengine.google.com/
GOOGLE_API_KEY=
GOOGLE_CSE_ID=

# ============================================
# OPTIONAL: Document Processing Settings
# Adjust these based on your hardware and use case
# ============================================
# Maximum file size for uploads (in MB)
MAX_FILE_SIZE_MB=10

# Text chunking for RAG
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=200

# Token limits
MAX_TOKEN_LIMIT=100000

# ============================================
# OPTIONAL: Model Default Settings
# These are defaults that can be overridden in the UI
# ============================================
DEFAULT_TEMPERATURE=0.0
DEFAULT_MAX_TOKENS=4000

# ============================================
# OPTIONAL: Search Configuration
# ============================================
MAX_SEARCH_RESULTS=10
SEARCH_TIMEOUT=60
API_RATE_LIMIT=20

# ============================================
# OPTIONAL: Authentication Settings
# ============================================
AUTH_COOKIE_NAME=st_research_v1
AUTH_COOKIE_KEY=random_secret_key_change_in_production
AUTH_COOKIE_EXPIRY_DAYS=30

# ============================================
# SETUP INSTRUCTIONS
# ============================================
# 1. Configure MongoDB (required):
#    - Install MongoDB locally OR use MongoDB Atlas
#    - Update MONGODB_URI above
#
# 2. Run database seeding scripts (first time only):
#    python scripts/seed_language_models.py
#    python scripts/seed_embedding_models.py
#    python scripts/seed_prompts.py  # Optional
#
# 3. Start the application:
#    streamlit run streamlit_app.py
#
# 4. Configure LLM providers (in the app):
#    - Go to Settings → LLM Providers
#    - Add API keys for your preferred providers:
#      * OpenAI (GPT-4, GPT-3.5)
#      * Anthropic (Claude)
#      * Google (Gemini)
#      * And 12+ more providers
#    - Test connection
#    - Start researching!
#
# ============================================
# SECURITY NOTES
# ============================================
# ✅ LLM API keys are stored in browser session only
# ✅ API keys are never saved to .env or database
# ✅ Each user configures their own API keys
# ✅ Keys are cleared when browser closes
# ✅ No API keys are persisted to disk
#
# For production deployments:
# - Use MongoDB authentication (update MONGODB_URI)
# - Enable TLS/SSL for MongoDB connections
# - Use strong AUTH_COOKIE_KEY
# - Enable HTTPS for the application
# - Restrict MongoDB access by IP
#
# ============================================
# SUPPORTED LLM PROVIDERS (Configured at Runtime)
# ============================================
# The following providers can be configured in the Settings page:
# 
# - OpenAI (gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo)
# - Anthropic (claude-3-5-sonnet, claude-3-opus, claude-3-sonnet)
# - Google Gemini (gemini-1.5-pro, gemini-1.5-flash)
# - Google Vertex AI (gemini models, text-bison)
# - AWS Bedrock (claude, llama, mistral models)
# - Azure OpenAI (custom deployments)
# - Cohere (command-r, command-r-plus)
# - Together AI (various open-source models)
# - Groq (fast inference for llama, mixtral)
# - Mistral AI (mistral-large, mistral-medium)
# - HuggingFace (inference API)
# - Ollama (local model hosting)
# - DeepSeek (deepseek-chat, deepseek-coder)
# - Perplexity AI (pplx models)
# - xAI (grok models)
# - NVIDIA AI (nemotron models)
#
# ============================================
# TROUBLESHOOTING
# ============================================
# MongoDB Connection Issues:
#   - Ensure MongoDB service is running
#   - Check MONGODB_URI format
#   - Verify network connectivity
#   - Check authentication credentials
#
# Provider Configuration Issues:
#   - Run seeding scripts if providers not showing
#   - Check MongoDB connection
#   - Verify database name matches
#
# For more help, see README.md
